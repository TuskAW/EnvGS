# MARK: Doesn't work: much larger model but not significantly better results

# These are configs for training on longer sequences using the Temporal Gaussian Hierarchy method
# Including initialization tuning, densification and opacity reset controlling
# And a deeper hierarchy for easier management of GPU memory
# Since we're training for long sequences, every bit of densification matter, thus it should never stop

configs: configs/specs/long.yaml

model_cfg:
    network_cfg:
        # densify_until_iter: 400000 # keep densifying
        # extra_prune_until_iter: 400000 # keep densifying
        points_dir:
            perframe_sparse: pcds_roma_3p_18k
